<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> [paper-review] 6-DOF GraspNet: Variational Grasp Generation for Object Manipulation | Joel Lee </title> <meta name="author" content="Joel Lee"> <meta name="description" content="paper review about 6-DOF GraspNet"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joonhyung-lee.github.io//blog/2023/6dof-graspnet/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Joel Lee </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">miscellaneous </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/repositories/">repositories</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/teaching/">teaching</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/gallery/">gallery</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">[paper-review] 6-DOF GraspNet: Variational Grasp Generation for Object Manipulation</h1> <p class="post-meta"> November 14, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/grsap"> <i class="fa-solid fa-hashtag fa-sm"></i> Grsap</a>   <a href="/blog/tag/vae"> <i class="fa-solid fa-hashtag fa-sm"></i> VAE</a>   <a href="/blog/tag/iccv"> <i class="fa-solid fa-hashtag fa-sm"></i> ICCV</a>   <a href="/blog/tag/2019"> <i class="fa-solid fa-hashtag fa-sm"></i> 2019</a>     ·   <a href="/blog/category/paper-review"> <i class="fa-solid fa-tag fa-sm"></i> paper-review</a>   <a href="/blog/category/paper-review-cv"> <i class="fa-solid fa-tag fa-sm"></i> paper-review/cv</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>ICCV 2019. [<a href="https://arxiv.org/abs/1905.10520" rel="external nofollow noopener" target="_blank">Paper</a>] [<a href="https://github.com/NVlabs/6dof-graspnet" rel="external nofollow noopener" target="_blank">Github</a>]</p> <p>Arsalan Mousavian, Clemens Eppner, Dieter Fox NVIDIA</p> <p>17 Aug 2019</p> </blockquote> <div align="center"> <img src="/assets/img/6dof-graspnet/6dof-graspnet-introudction.png" width="75%"> <p>Fig. 1: Introduction figure about 6-dof graspnet paper.</p> </div> <h3 id="summary">Summary</h3> <p>The paper addresses the challenge of robotic object manipulation, specifically the generation of grasp poses. The author formulates the problem as sampling a set of grasps using a variational autoencoder (VAE) and refining these grasps with a grasp evaluator model. The key contribution of the approach is to generate diverse and stable grasps of unknown objects using 3D point clouds from a depth camera.</p> <h3 id="methodology">Methodology:</h3> <div align="center"> <img src="/assets/img/6dof-graspnet/6dof-graspnet-framework.png" width="100%"> <p>Fig. 2: Overall framework about 6-dof graspnet.</p> </div> <p>The author introduces a two-fold architecture: (1) a VAE for sampling diverse grasps and (2) a grasp evaluator network for refining these grasps. The VAE is trained to map partial point clouds of objects to a diverse set of grasps. The evaluator assesses and refines these grasps based on grasp quality.</p> <div align="center"> <img src="/assets/img/6dof-graspnet/6dof-graspnet-vae.png" width="100%"> <p>Fig. 3: VAE network about 6-dof graspnet.</p> </div> <p>Network Architecture: Training is conducted using simulated data for grasp generation. The network is based on the PointNet++ architecture, which effectively handles 3D point cloud data. After initial grasp generation, the grasps are iteratively refined using the evaluator network, enhancing both the success rate and the diversity of the grasps.</p> <h3 id="experiments--evaluation">Experiments &amp; Evaluation:</h3> <div align="center"> <img src="/assets/img/6dof-graspnet/6dof-graspnet-environement.png" width="100%"> <p>Fig. 4: Environmental setting about 6-dof graspnet.</p> </div> <p>Simulation-Based Training: The model is trained using data generated from physics simulations, FleX, ensuring a wide range of object shapes and grasp types. Real-World Robot Experiments: The author tests the model in real-world scenarios with a Franka Panda manipulator. The experiments involve picking up various objects, demonstrating the model’s ability to generate successful grasps in a physical environment. Evaluation Metrics: The success rate and coverage rate of grasps are used as metrics, with the model showing high performance in both aspects.</p> <div align="center"> <img src="/assets/img/6dof-graspnet/result-table.png" width="100%"> <p>Fig. 5: Result Table.</p> </div> <div align="center"> <img src="/assets/img/6dof-graspnet/result-refinement.png" width="100%"> <p>Fig. 6: Result of Refinement Network.</p> </div> <h3 id="conclusion">Conclusion:</h3> <p>This paper makes a significant step in robotic grasp generation by combining deep learning with physics simulator to obtain efficient, diverse, and successful grasps for object manipulation. The model’s success in both simulated and real-world tests underlines its potential for broad applications in robotics.</p> <h3 id="thoughts">Thoughts:</h3> <p>The author presents an innovative approach to robotic grasp generation using a variational autoencoder and a grasp evaluator to handle a wide range of objects. The paper is the first to introduce both a learning-based method for generating grasp poses (i.e., learned grasp sampler) and a gradient-based optimization technique for improving these grasp poses (i.e., gradient-based refinement process). Trained with simulated data and validated with real-world experiments, the model effectively generates and refines grasp poses using 3D point clouds. Despite its reliance on simulated data, the paper shows a significant advancement in robotic manipulation, demonstrates practical applications.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/dream2real/">[paper-review] Dream2Real: Zero-Shot 3D Object Rearrangement with Vision-Language Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/copa/">[paper-review] CoPa: General Robotic Manipulation through Spatial Constraints of Parts with Foundational Model</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/vq/">[study] Vector Quantization</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/aligndiff/">[paper-review] AlignDiff: Aligning Diverse Human Preferences via Behavior-customisable Diffusion Model</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/rbc/">[paper-review] Reactive Base Control for On-The-Move Mobile Manipulation in Dynamic Environments</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"joonhyung-lee/joonhyung-lee.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Joel Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>